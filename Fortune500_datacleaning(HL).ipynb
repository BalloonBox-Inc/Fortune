{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: @michaelbrink\n",
    "#Org: BalloonBox Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_type_transform(df_origin):\n",
    "\n",
    "    # Make a copy\n",
    "    df = df_origin.copy()\n",
    "\n",
    "    # The list of text features that don't need to clean\n",
    "    text_list=['Name','Country','Headquarters','Industry','CEO','Website','Company Type','Ticker']\n",
    "\n",
    "    # The list of all the features\n",
    "    feature_list=df.columns\n",
    "    \n",
    "    # For loop for cleaninn\n",
    "    for col in feature_list: \n",
    "        # Text data doesn't need to clean\n",
    "        if col in text_list:\n",
    "            pass\n",
    "        else:\n",
    "            # 1: The '-' value in '%' columns gonna be 0!\n",
    "            df[col] = df[col].replace(to_replace='[\\$,%]',value='',regex=True)\n",
    "\n",
    "            # 2: The '-' value in ($M) columns will be dropped\n",
    "            if ('%' in col) or ('Change' in col) or ('Return' in col):\n",
    "                df[col] = df[col].replace(to_replace='^-$',value='0',regex=True)\n",
    "            \n",
    "            # 3: Convert them into numeric values\n",
    "            df[col] = pd.to_numeric(df[col],errors='coerce')\n",
    "            \n",
    "            # # 4: Divide by 100 for all '%' columns\n",
    "            # if ('%' in col) or ('Return' in col):\n",
    "            #     df[col] = round(df[col]/100,5)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_by_quantile(df_origin,cols):\n",
    "    '''\n",
    "        df is the dataframe we want to process: DataFrame\n",
    "        cols is a list of columns we want to process: List\n",
    "    '''\n",
    "    # Make a copy of DataFrame\n",
    "    df = df_origin.copy()\n",
    "\n",
    "    # List contains the index of dropped rows\n",
    "    drop_list = []\n",
    "\n",
    "    for col in cols:\n",
    "        # drop the outliers based on boxplot\n",
    "        temp = list(df[col].quantile([0.25,0.75]))\n",
    "        Q1 = temp[0]\n",
    "        Q3 = temp[1]\n",
    "        IQR = Q3-Q1\n",
    "        minimum = Q1-1.5*IQR\n",
    "        maximum = Q3+1.5*IQR\n",
    "        # Append the index of dropped rows\n",
    "        low_outlier = df[df[col]<=minimum].index\n",
    "        high_outlier = df[df[col]>=maximum].index\n",
    "        for index in low_outlier:\n",
    "            drop_list.append(index)\n",
    "        for index in high_outlier:\n",
    "            drop_list.append(index)\n",
    "        \n",
    "        # Deduplicated index\n",
    "        drop_list = list(dict.fromkeys(drop_list))\n",
    "    \n",
    "    # Drop the outliers\n",
    "    df.drop(drop_list,axis=0,inplace=True)\n",
    "\n",
    "    # # Histogram\n",
    "    # plt.hist(df['Employees'],bins=5)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_buckets(df_origin,cols):\n",
    "    # Make a copy of origin dataset\n",
    "    df = df_origin.copy()\n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "    # Create 5 equal size buckets\n",
    "    for col in cols:\n",
    "        col_value = df[col]\n",
    "        qcut_value, bins = pd.qcut(x=col_value,q=[0,0.2,0.4,0.6,0.8,1.0],labels=[1,2,3,4,5],retbins=True)\n",
    "        temp_df[col+'_cat'] = qcut_value\n",
    "        # print('The bins of {col} is : {bins}'.format(col=col,bins=bins))\n",
    "    \n",
    "    # Concat the dataFrame\n",
    "    df = pd.concat([df,temp_df],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the original datasets\n",
    "df_all_origin=pd.read_csv('Fortune500.csv')\n",
    "df_detail_origin=pd.read_csv('Fortune500-2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The shape of original df_all is : (4000, 14)\nThe shape of df_all after dropping null value is :  (3774, 14)\nThe shape of df_all after dropping outliers is :  (2801, 14)\nThe shape of df_all after creating buckets is :  (2801, 18)\n"
    }
   ],
   "source": [
    "# Back up the original dataset\n",
    "df_all = df_all_origin.copy()\n",
    "print('The shape of original df_all is :',df_all.shape)\n",
    "\n",
    "\n",
    "# Data type transformation for df_all dataset\n",
    "df_all = data_type_transform(df_all)\n",
    "\n",
    "\n",
    "# Drop null values\n",
    "if df_all.isna().sum().sum() != 0:\n",
    "    df_all.dropna(inplace=True)\n",
    "print('The shape of df_all after dropping null value is : ',df_all.shape)\n",
    "\n",
    "\n",
    "# Drop outliers\n",
    "drop_cols = ['Profit ($M)','Assets ($M)','Market Value ($M)','Employees']\n",
    "df_all = drop_by_quantile(df_all,drop_cols)\n",
    "print('The shape of df_all after dropping outliers is : ',df_all.shape)\n",
    "\n",
    "\n",
    "# Create three buckets for Revenue(1:Low, 2:Medium, 3:High)\n",
    "conditions = [df_all['Revenue ($M)']<5000,(df_all['Revenue ($M)']>=5000)&(df_all['Revenue ($M)']<=10000),df_all['Revenue ($M)']>10000]\n",
    "values = [1,2,3]\n",
    "df_all['Revenue_cat'] = np.select(conditions,values)\n",
    "\n",
    "\n",
    "# Combine filter's columns together(0: No filter, 1: Female CEO, 2: Founder CEO, 3: Both)\n",
    "conditions = [(df_all['Female CEO']==0)&(df_all['Founder CEO']==0),\\\n",
    "              (df_all['Female CEO']==1)&(df_all['Founder CEO']==0),\\\n",
    "              (df_all['Female CEO']==0)&(df_all['Founder CEO']==1),\\\n",
    "              (df_all['Female CEO']==1)&(df_all['Founder CEO']==1)]\n",
    "values = [0,1,2,3]\n",
    "df_all['Filter_cat'] = np.select(conditions,values)\n",
    "if 'Female CEO' or 'Founder CEO' in df_all.columns:\n",
    "    df_all.drop(columns=['Female CEO','Founder CEO'],inplace=True)\n",
    "\n",
    "\n",
    "# Create buckets\n",
    "process_list = ['Profit ($M)','Assets ($M)','Market Value ($M)','Employees']\n",
    "df_all = create_buckets(df_all,process_list)\n",
    "print('The shape of df_all after creating buckets is : ',df_all.shape)\n",
    "\n",
    "# # Create buckets for df_all\n",
    "# process_list = ['Filter_Cat','Profit ($M)_Cat','Assets ($M)_Cat','Market Value ($M)_Cat','Employees_Cat']\n",
    "# df_all = dummies(df_all,process_list)\n",
    "# print('The shape of df_all after getting dummies is : ',df_all.shape)\n",
    "# df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Rank', 'Name', 'Revenue ($M)', 'Revenue % change', 'Profit ($M)',\n       'Profit % change', 'Assets ($M)', 'Market Value ($M)',\n       'Change in rank (1000)', 'Employees', 'Change in rank (500)', 'Year',\n       'Revenue_cat', 'Filter_cat', 'Profit ($M)_cat', 'Assets ($M)_cat',\n       'Market Value ($M)_cat', 'Employees_cat'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(df_origin,cols):\n",
    "    # Make a copy of origin dataset\n",
    "    df = df_origin.copy()\n",
    "    temp_df =pd.get_dummies(df['Profit ($M)_cat'])\n",
    "    display(temp_df)\n",
    "    # # Concat the dataFrame\n",
    "    # df = pd.concat([df,temp_df],axis=1)\n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "      1  2  3  4  5\n10    0  0  0  0  1\n14    0  0  0  0  1\n33    0  0  0  0  1\n36    0  0  0  0  1\n44    0  0  0  0  1\n...  .. .. .. .. ..\n3995  0  0  1  0  0\n3996  0  1  0  0  0\n3997  0  1  0  0  0\n3998  1  0  0  0  0\n3999  1  0  0  0  0\n\n[2801 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2801 rows × 5 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "dummies(df_all,['Filter_cat','Profit ($M)_cat','Assets ($M)_cat','Market Value ($M)_cat','Employees_cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing(String to Numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstly, drop the duplicated and useless columns in df_detail\n",
    "feature_list = df_detail.columns\n",
    "drop_list = ['Revenues ($M).1','Profits ($M).1','Unnamed: 25']\n",
    "for feature in feature_list:\n",
    "    if feature in drop_list:\n",
    "        df_detail.drop(columns=feature,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data cleaning for df_detail dataset\n",
    "df_detail_cleaned = data_cleaning(df_detail)\n",
    "\n",
    "print('The shape of original df_detail is :',df_detail.shape)\n",
    "\n",
    "# Drop null value\n",
    "if df_detail_cleaned.isna().sum().sum() != 0:\n",
    "    df_detail_cleaned.dropna(inplace=True)\n",
    "\n",
    "print('The shape of cleaned de_detail is : ',df_detail_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning(Drop outilers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process df_detail_cleaned dataset\n",
    "drop_cols = ['Profits ($M)','Market Value ($M)','Employees','Assets ($M)',\\\n",
    "             'Total Stockholder Equity ($M)','Earnings Per Share ($)']\n",
    "df_detail_dropped = drop_by_quantile(df_detail_cleaned,drop_cols)\n",
    "\n",
    "# Results from each step\n",
    "print('The shape of original df_all is :',df_detail.shape)\n",
    "print('The shape of cleaned df_all is : ',df_detail_cleaned.shape)\n",
    "print('The shape of dropped df_all(quantiles) is : ',df_detail_dropped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing(Numerics to categoricals, equal size buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dummy process for df_detail\n",
    "process_list = ['Revenues ($M)','Profits ($M)','Market Value ($M)','Employees','Assets ($M)',\\\n",
    "             'Total Stockholder Equity ($M)','Earnings Per Share ($)']\n",
    "df_detail_cat = create_buckets(df_detail_dropped,process_list)\n",
    "\n",
    "# Results from each step\n",
    "print('\\n')\n",
    "print('The shape of original df_all is :',df_detail.shape)\n",
    "print('The shape of cleaned df_all is : ',df_detail_cleaned.shape)\n",
    "print('The shape of dropped df_all(quantiles) is : ',df_detail_dropped.shape)\n",
    "print('The shape of categorized df_all is : ',df_detail_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the csv files\n",
    "df_all_final.to_csv('Fortune500_cleaned.csv',index=False)\n",
    "df_detail_final.to_csv('Fortune500-2_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python_defaultSpec_1597634167825"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
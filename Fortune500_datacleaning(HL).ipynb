{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: @michaelbrink\n",
    "#Org: BalloonBox Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the original datasets\n",
    "df_all=pd.read_csv('Fortune500.csv')\n",
    "df_detail=pd.read_csv('Fortune500-2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# firstly, drop the duplicated and useless columns in df_detail\n",
    "feature_list = df_detail.columns\n",
    "drop_list = ['Revenues ($M).1','Profits ($M).1','Unnamed: 25']\n",
    "for feature in feature_list:\n",
    "    if feature in drop_list:\n",
    "        df_detail.drop(columns=feature,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_cleaning(df_origin):\n",
    "\n",
    "    # Make a copy\n",
    "    df = df_origin.copy()\n",
    "\n",
    "    # The list of text features that don't need to clean\n",
    "    text_list=['Name','Country','Headquarters','Industry','CEO','Website','Company Type','Ticker']\n",
    "\n",
    "    # The list of all the features\n",
    "    feature_list=df.columns\n",
    "\n",
    "    # For loop for cleaning\n",
    "    for col in feature_list:\n",
    "        # Text data doesn't need to clean\n",
    "        if col in text_list:\n",
    "            pass\n",
    "        else:\n",
    "            # 1: The '-' value in '%' columns gonna be 0!\n",
    "            df[col] = df[col].replace(to_replace='[\\$,%]',value='',regex=True)\n",
    "\n",
    "            # 2: The '-' value in ($M) columns will be dropped\n",
    "            if ('%' in col) or ('Change' in col) or ('Return' in col):\n",
    "                df[col] = df[col].replace(to_replace='^-$',value='0',regex=True)\n",
    "            \n",
    "            # 3: Convert them into numeric values\n",
    "            df[col] = pd.to_numeric(df[col],errors='coerce')\n",
    "            \n",
    "            # # 4: Divide by 100 for all '%' columns\n",
    "            # if ('%' in col) or ('Return' in col):\n",
    "            #     df[col] = round(df[col]/100,5)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The shape of original df_all is : (4000, 14)\nThe shape of cleaned df_all is :  (3774, 14)\n"
    }
   ],
   "source": [
    "# Data cleaning for df_all dataset\n",
    "df_all_cleaned = data_cleaning(df_all)\n",
    "\n",
    "print('The shape of original df_all is :',df_all.shape)\n",
    "\n",
    "# Drop null value\n",
    "if df_all_cleaned.isna().sum().sum() != 0:\n",
    "    df_all_cleaned.dropna(inplace=True)\n",
    "\n",
    "print('The shape of cleaned df_all is : ',df_all_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The shape of original df_detail is : (1000, 23)\nThe shape of cleaned de_detail is :  (924, 23)\n"
    }
   ],
   "source": [
    "# Data cleaning for df_detail dataset\n",
    "df_detail_cleaned = data_cleaning(df_detail)\n",
    "\n",
    "print('The shape of original df_detail is :',df_detail.shape)\n",
    "\n",
    "# Drop null value\n",
    "if df_detail_cleaned.isna().sum().sum() != 0:\n",
    "    df_detail_cleaned.dropna(inplace=True)\n",
    "\n",
    "print('The shape of cleaned de_detail is : ',df_detail_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_by_quantile(df_origin,cols):\n",
    "    '''\n",
    "        df is the dataframe we want to process: DataFrame\n",
    "        cols is a list of columns we want to process: List\n",
    "    '''\n",
    "    # Make a copy of DataFrame\n",
    "    df = df_origin.copy()\n",
    "\n",
    "    # List contains the index of dropped rows\n",
    "    drop_list = []\n",
    "\n",
    "    for col in cols:\n",
    "        # drop the outliers based on boxplot\n",
    "        temp = list(df[col].quantile([0.25,0.75]))\n",
    "        Q1 = temp[0]\n",
    "        Q3 = temp[1]\n",
    "        IQR = Q3-Q1\n",
    "        minimum = Q1-1.5*IQR\n",
    "        maximum = Q3+1.5*IQR\n",
    "        # Append the index of dropped rows\n",
    "        low_outlier = df[df[col]<=minimum].index\n",
    "        high_outlier = df[df[col]>=maximum].index\n",
    "        for index in low_outlier:\n",
    "            drop_list.append(index)\n",
    "        for index in high_outlier:\n",
    "            drop_list.append(index)\n",
    "        \n",
    "        # Deduplicated index\n",
    "        drop_list = list(dict.fromkeys(drop_list))\n",
    "    \n",
    "    # Drop the outliers\n",
    "    df.drop(drop_list,axis=0,inplace=True)\n",
    "\n",
    "    # # Histogram\n",
    "    # plt.hist(df['Employees'],bins=5)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The shape of original df_all is : (4000, 14)\nThe shape of cleaned df_all is :  (3774, 14)\nThe shape of dropped df_all(quantiles) is :  (2755, 14)\n"
    }
   ],
   "source": [
    "# Process df_all_cleaned dataset\n",
    "drop_cols = ['Revenue ($M)','Profit ($M)','Assets ($M)','Market Value ($M)','Employees']\n",
    "df_all_dropped = drop_by_quantile(df_all_cleaned,drop_cols)\n",
    "\n",
    "# Results from each step\n",
    "print('The shape of original df_all is :',df_all.shape)\n",
    "print('The shape of cleaned df_all is : ',df_all_cleaned.shape)\n",
    "print('The shape of dropped df_all(quantiles) is : ',df_all_dropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The shape of original df_all is : (1000, 23)\nThe shape of cleaned df_all is :  (924, 23)\nThe shape of dropped df_all(quantiles) is :  (611, 23)\n"
    }
   ],
   "source": [
    "# Process df_detail_cleaned dataset\n",
    "drop_cols = ['Revenues ($M)','Profits ($M)','Market Value ($M)','Employees','Assets ($M)',\\\n",
    "             'Total Stockholder Equity ($M)','Earnings Per Share ($)']\n",
    "df_detail_dropped = drop_by_quantile(df_detail_cleaned,drop_cols)\n",
    "\n",
    "# Results from each step\n",
    "print('The shape of original df_all is :',df_detail.shape)\n",
    "print('The shape of cleaned df_all is : ',df_detail_cleaned.shape)\n",
    "print('The shape of dropped df_all(quantiles) is : ',df_detail_dropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_buckets(df_origin,cols):\n",
    "    # Make a copy of origin dataset\n",
    "    df = df_origin.copy()\n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "    # Create 5 equal size buckets\n",
    "    for col in cols:\n",
    "        col_value = df[col]\n",
    "        qcut_value, bins = pd.qcut(x=col_value,q=[0,0.2,0.4,0.6,0.8,1.0],labels=[1,2,3,4,5],retbins=True)\n",
    "        temp_df[col+'_cat'] = qcut_value\n",
    "    \n",
    "    # Get dummies\n",
    "    temp_df = pd.get_dummies(temp_df)\n",
    "\n",
    "    # Concat the dataFrame together\n",
    "    df = pd.concat([df,temp_df],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The shape of original df_all is : (4000, 14)\nThe shape of cleaned df_all is :  (3774, 14)\nThe shape of dropped df_all(quantiles) is :  (2755, 14)\nThe shape of final df_all is :  (2755, 34)\n"
    }
   ],
   "source": [
    "# Dummy process\n",
    "dummy_list = ['Profit ($M)','Assets ($M)','Market Value ($M)','Employees']\n",
    "df_all_final = create_buckets(df_all_dropped,dummy_list)\n",
    "\n",
    "# Results from each step\n",
    "print('The shape of original df_all is :',df_all.shape)\n",
    "print('The shape of cleaned df_all is : ',df_all_cleaned.shape)\n",
    "print('The shape of dropped df_all(quantiles) is : ',df_all_dropped.shape)\n",
    "print('The shape of final df_all is : ',df_all_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The shape of original df_all is : (1000, 23)\nThe shape of cleaned df_all is :  (924, 23)\nThe shape of dropped df_all(quantiles) is :  (611, 23)\nThe shape of final df_all is :  (611, 53)\n"
    }
   ],
   "source": [
    "# Dummy process\n",
    "dummy_list = ['Profits ($M)','Market Value ($M)','Employees','Assets ($M)',\\\n",
    "             'Total Stockholder Equity ($M)','Earnings Per Share ($)']\n",
    "df_detail_final = create_buckets(df_detail_dropped,dummy_list)\n",
    "\n",
    "# Results from each step\n",
    "print('The shape of original df_all is :',df_detail.shape)\n",
    "print('The shape of cleaned df_all is : ',df_detail_cleaned.shape)\n",
    "print('The shape of dropped df_all(quantiles) is : ',df_detail_dropped.shape)\n",
    "print('The shape of final df_all is : ',df_detail_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the csv files\n",
    "df_all_final.to_csv('Fortune500_cleaned.csv',index=False)\n",
    "df_detail_final.to_csv('Fortune500-2_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python_defaultSpec_1597634167825"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}